2021-01-03 12:43:06.838686: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Dummies : [0, 1, 2, 3, 4, 5, 42, 43, 44, 45, 46, 47, 48]
Dummy note
Dummy note
Dummy note
Dummy note
Dummy note
Dummy note
For 6 nbtrain = 24055, nbtest = 6015
For 7 nbtrain = 58380, nbtest = 14597
For 8 nbtrain = 56838, nbtest = 14210
For 9 nbtrain = 21930, nbtest = 5484
For 10 nbtrain = 89730, nbtest = 22434
For 11 nbtrain = 22051, nbtest = 5514
For 12 nbtrain = 83854, nbtest = 20965
For 13 nbtrain = 34177, nbtest = 8546
For 14 nbtrain = 38497, nbtest = 9626
For 15 nbtrain = 85353, nbtest = 21341
For 16 nbtrain = 23927, nbtest = 5984
For 17 nbtrain = 84061, nbtest = 21017
For 18 nbtrain = 25957, nbtest = 6490
For 19 nbtrain = 87853, nbtest = 21967
For 20 nbtrain = 65884, nbtest = 16472
For 21 nbtrain = 33067, nbtest = 8268
For 22 nbtrain = 83176, nbtest = 20797
For 23 nbtrain = 25979, nbtest = 6498
For 24 nbtrain = 101472, nbtest = 25372
For 25 nbtrain = 41111, nbtest = 10279
For 26 nbtrain = 50087, nbtest = 12524
For 27 nbtrain = 68049, nbtest = 17015
For 28 nbtrain = 22984, nbtest = 5749
For 29 nbtrain = 65069, nbtest = 16268
For 30 nbtrain = 21093, nbtest = 5275
For 31 nbtrain = 48768, nbtest = 12195
For 32 nbtrain = 36088, nbtest = 9024
For 33 nbtrain = 18022, nbtest = 4507
For 34 nbtrain = 39890, nbtest = 9974
For 35 nbtrain = 11204, nbtest = 2802
For 36 nbtrain = 32911, nbtest = 8229
For 37 nbtrain = 13030, nbtest = 3259
For 38 nbtrain = 14172, nbtest = 3545
For 39 nbtrain = 19647, nbtest = 4914
For 40 nbtrain = 5403, nbtest = 1352
For 41 nbtrain = 12937, nbtest = 3236
Dummy note
Dummy note
Dummy note
Dummy note
Dummy note
Dummy note
Dummy note
6   (24055, 7)   (24055,)   [0 1]
7   (58380, 7)   (58380,)   [0 1]
8   (56838, 7)   (56838,)   [0 1]
9   (21930, 7)   (21930,)   [0 1]
10   (89730, 7)   (89730,)   [0 1 2]
11   (22051, 7)   (22051,)   [0 1 2]
12   (83854, 7)   (83854,)   [0 1 2]
13   (34177, 7)   (34177,)   [0 1 2]
14   (38497, 7)   (38497,)   [0 1 2]
15   (85353, 7)   (85353,)   [0 1 2 3]
16   (23927, 7)   (23927,)   [0 1 2 3]
17   (84061, 7)   (84061,)   [0 1 2 3]
18   (25957, 7)   (25957,)   [0 1 2 3]
19   (87853, 7)   (87853,)   [0 1 2 3 4]
20   (65884, 7)   (65884,)   [0 1 2 3 4]
21   (33067, 7)   (33067,)   [0 1 2 3 4]
22   (83176, 7)   (83176,)   [0 1 2 3 4]
23   (25979, 7)   (25979,)   [0 1 2 3 4]
24   (101472, 7)   (101472,)   [0 1 2 3 4 5]
25   (41111, 7)   (41111,)   [0 1 2 3 4]
26   (50087, 7)   (50087,)   [0 1 2 3 4]
27   (68049, 7)   (68049,)   [0 1 2 3 4]
28   (22984, 7)   (22984,)   [0 1 2 3 4]
29   (65069, 7)   (65069,)   [0 1 2 3 4]
30   (21093, 7)   (21093,)   [0 1 2 3]
31   (48768, 7)   (48768,)   [0 1 2 3]
32   (36088, 7)   (36088,)   [0 1 2 3]
33   (18022, 7)   (18022,)   [0 1 2 3]
34   (39890, 7)   (39890,)   [0 1 2 3]
35   (11204, 7)   (11204,)   [0 1 2]
36   (32911, 7)   (32911,)   [0 1 2]
37   (13030, 7)   (13030,)   [0 1 2]
38   (14172, 7)   (14172,)   [0 1 2]
39   (19647, 7)   (19647,)   [0 1 2]
40   (5403, 7)   (5403,)   [0 1]
41   (12937, 7)   (12937,)   [0 1]
AAA [0 1]
note 6
[[3029  587]
 [ 662 1737]]
AAA [0 1]
note 7
[[9270  612]
 [2087 2628]]
AAA [0 1]
note 8
[[10873   360]
 [ 2019   958]]
AAA [0 1]
note 9
[[4136  148]
 [ 475  725]]
AAA [0 1 2]
note 10
[[8793 2046   15]
 [1976 8365    3]
 [ 730  429   77]]
AAA [0 1 2]
note 11
[[1533  707    0]
 [ 789 2026    0]
 [ 281  178    0]]
AAA [0 1 2]
note 12
[[10189  1641     9]
 [ 3289  4772    32]
 [  807   130    96]]
AAA [0 1 2]
note 13
[[5651  331    9]
 [1433  795    0]
 [ 253   31   43]]
AAA [0 1 2]
note 14
[[5869  566    0]
 [1237 1661    0]
 [ 268   25    0]]
AAA [0 1 2 3]
note 15
[[9264 1426    2    1]
 [2378 5848    2    0]
 [1482  497   51    0]
 [ 110  216    0   64]]
AAA [0 1 2 3]
note 16
[[1713  768    8    0]
 [ 655 2111   10    0]
 [ 312  264   38    0]
 [  43   62    0    0]]
AAA [0 1 2 3]
note 17
[[11054   986     0     0]
 [ 2910  4552     0     0]
 [ 1061   301     0     0]
 [   79    65     0     9]]
AAA [0 1 2 3]
note 18
[[3673  309    1   11]
 [ 850 1124    0    7]
 [ 294   73    2    0]
 [  50   38    0   58]]
AAA [0 1 2 3 4]
note 19
[[7484 1892  309    0    0]
 [1691 4837  193    2    1]
 [2187 1229 1236    0    1]
 [ 181  490  115    1    0]
 [  57   34   25    0    2]]
AAA [0 1 2 3 4]
note 20
[[5167 1738  135    0    0]
 [2066 4064  158    0    0]
 [1221  915  396    0    0]
 [ 264  287   25    9    0]
 [  13    9    5    0    0]]
AAA [0 1 2 3 4]
note 21
[[3139  718    5    0    0]
 [ 801 2265    0    0    0]
 [ 758  224   22    0    0]
 [  59  249    0    6    0]
 [  11   11    0    0    0]]
AAA [0 1 2 3 4]
note 22
[[9301 1605    6    0    1]
 [3380 3971    5    0    3]
 [1369  683   46    0    4]
 [ 258   97    2    0    0]
 [  23    7    0    0   36]]
AAA [0 1 2 3 4]
note 23
[[2812  516    3    0    0]
 [1076 1329   14    0    0]
 [ 390  171   49    0    0]
 [  80   34    2    0    0]
 [  20    2    0    0    0]]
AAA [0 1 2 3 4 5]
note 24
[[8802 1333  515   13    0    0]
 [3051 3589  391   12    0    0]
 [3482  721 1617   23    0    0]
 [ 862  367  194  166    0    0]
 [ 160   27   30    4    0    0]
 [   7    4    2    0    0    0]]
AAA [0 1 2 3 4]
note 25
[[2685  997  151    0    0]
 [ 911 2372  125    0    0]
 [ 801  600  910    0    0]
 [ 209  371  107    0    0]
 [  11   26    3    0    0]]
AAA [0 1 2 3 4]
/home/delairra/.local/lib/python3.8/site-packages/sklearn/metrics/_plot/confusion_matrix.py:81: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
note 26
[[4441  959   22    5    0]
 [1534 2832   25    3    0]
 [1342  539  202    5    0]
 [ 311  124   28   57    0]
 [  59   36    0    0    0]]
AAA [0 1 2 3 4]
note 27
[[5716 1648   76    0    0]
 [1811 3485  140    0    0]
 [1301  723 1295    0    0]
 [ 347  347   76    6    0]
 [  21   23    0    0    0]]
AAA [0 1 2 3 4]
note 28
[[2193  444   54    0    0]
 [ 773 1043   50    0    0]
 [ 431  281  259    0    0]
 [ 132   59    7    0    0]
 [   9   12    2    0    0]]
AAA [0 1 2 3 4]
note 29
[[7817  894   97    0   13]
 [2006 2193   94    0    6]
 [1425  260 1124    0    8]
 [ 188   83    5    0    0]
 [  23   13    1    0   18]]
AAA [0 1 2 3]
note 30
[[2802  294    6    0]
 [ 656  548   11    0]
 [ 694  112   54    0]
 [  61   36    1    0]]
AAA [0 1 2 3]
note 31
[[5933  874    5    0]
 [1731 2220    9    0]
 [1027  235   45    0]
 [  60   56    0    0]]
AAA [0 1 2 3]
note 32
[[5124  414    0    0]
 [1401 1157    0    0]
 [ 690  169   14    0]
 [  38   17    0    0]]
AAA [0 1 2 3]
note 33
[[2569  259    2    0]
 [ 709  650    0    0]
 [ 245   47    8    0]
 [  14    4    0    0]]
AAA [0 1 2 3]
note 34
[[5700  456    0    0]
 [1313 1892    0    0]
 [ 537   62    0    0]
 [  12    2    0    0]]
AAA [0 1 2]
note 35
[[1936   69    0]
 [ 462  197    0]
 [ 124   14    0]]
AAA [0 1 2]
note 36
[[5727  287    0]
 [1337  641    0]
 [ 211   21    5]]
AAA [0 1 2]
note 37
[[2485   65    0]
 [ 473  185    0]
 [  50    1    0]]
AAA [0 1 2]
note 38
[[2839   74    0]
 [ 410  177    0]
 [  42    3    0]]
AAA [0 1 2]
note 39
[[4234   39    0]
 [ 513   99    0]
 [  29    0    0]]
AAA [0 1]
note 40
[[1186    0]
 [ 166    0]]
AAA [0 1]
note 41
[[2991    0]
 [ 245    0]]